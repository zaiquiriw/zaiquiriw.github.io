
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="All things ZaiquiriW" name="description"/>
<meta content="Zachary Canoot &amp; Gray Simpson" name="author"/>
<link href="https://zaiquiri.github.io/ML%20Work/Classification/" rel="canonical"/>
<link href="../../tags/" rel="prev"/>
<link href="../Regression/" rel="next"/>
<link href="../../assets/meta/favicons.png" rel="icon"/>
<meta content="mkdocs-1.5.3, mkdocs-material-9.4.6" name="generator"/>
<title>Classification - ZaiquiriW</title>
<link href="../../assets/stylesheets/main.35e1ed30.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.356b1318.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Ubuntu";--md-code-font:"Ubuntu Mono"}</style>
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet"/>
<link href="https://cdn.jsdelivr.net/gh/ObsidianPublisher/assets@main/dist/styles.css" rel="stylesheet"/>
<link href="../../assets/css/admonition.css" rel="stylesheet"/>
<link href="../../assets/css/custom_attributes.css" rel="stylesheet"/>
<link href="../../assets/css/customization.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script src="https://unpkg.com/@popperjs/core@2/dist/umd/popper.min.js"></script>
<script src="https://unpkg.com/tippy.js@6/dist/tippy-bundle.umd.js"></script>
<link href="https://unpkg.com/tippy.js@6/animations/scale-subtle.css" rel="stylesheet">
<link href="https://unpkg.com/tippy.js@6/themes/translucent.css" rel="stylesheet">
<link crossorigin="anonymous" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" integrity="sha512-Fo3rlrZj/k7ujTnHg4CGR2D7kSs0v4LLanw2qksYuRlEzO+tcaEPQogQ0KaoGN26/zrn20ImR1DfuLWnOo7aBA==" referrerpolicy="no-referrer" rel="stylesheet">
<meta content="summary_large_image" name="twitter:card"/>
<meta content="https://zaiquiri.github.io/assets/meta/SEO.png" property="og:image"/>
<meta content="https://zaiquiri.github.io/assets/meta/SEO.png" name="twitter:image"/>
<meta content="https://zaiquiri.github.io/" name="site_url"/>
<meta content="Classification" property="og:title"/>
<meta content="Classification" name="twitter:title"/>
<meta content="All things ZaiquiriW" name="og:description"/>
<meta content="All things ZaiquiriW" name="twitter:description"/>
<script> document.title = "Classification" </script>
</link></link></link> <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
        html.glightbox-open { overflow: initial; height: 100%; }
        .gslide-title { margin-top: 0px; user-select: text; }
        .gslide-desc { color: #666; user-select: text; }
        .gslide-image img { background: white; }
        
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
            </style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="light-blue" data-md-color-primary="teal" data-md-color-scheme="default" dir="ltr">
<script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#classification">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="ZaiquiriW" class="md-header__button md-logo" data-md-component="logo" href="../.." title="ZaiquiriW">
<img alt="logo" src="../../assets/meta/favicons.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            ZaiquiriW
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Classification
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="light-blue" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="teal" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="blue" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"></path></svg>
</label>
</form>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
<div class="md-search__suggest" data-md-component="search-suggest"></div>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../..">
        
  
    
  
  Home

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../tags/">
        
  
    
  
  Tags

      </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="./">
          
  
    
  
  ML Work

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../obsidian/copart%20internship/">
          
  
    
  
  Obsidian

        </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="ZaiquiriW" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="ZaiquiriW">
<img alt="logo" src="../../assets/meta/favicons.png"/>
</a>
    ZaiquiriW
  </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../..">
<span class="md-ellipsis">
    Home
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tags/">
<span class="md-ellipsis">
    Tags
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
<span class="md-ellipsis">
    ML Work
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            ML Work
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Classification
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    Classification
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#classification">
    Classification
  </a>
<nav aria-label="Classification" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#what-is-our-data">
    What is Our Data?
  </a>
<nav aria-label="What is Our Data?" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#reading-the-data">
    Reading the Data
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#training-data-exploration">
    Training Data Exploration
  </a>
<nav aria-label="Training Data Exploration" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#spliting-training-data">
    Spliting Training Data
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#textual-measurements">
    Textual Measurements
  </a>
<nav aria-label="Textual Measurements" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#text-analysis-conclusion">
    Text Analysis Conclusion
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#visual-analysis">
    Visual Analysis
  </a>
<nav aria-label="Visual Analysis" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#visual-analysis-conclusion">
    Visual Analysis Conclusion
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#classification-regression">
    Classification Regression
  </a>
<nav aria-label="Classification Regression" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#logistic-regression">
    Logistic Regression
  </a>
<nav aria-label="Logistic Regression" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#explanation">
    Explanation
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#looking-at-p-values">
    Looking at P-Values
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#probability-warning">
    Probability Warning
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#initial-impressions">
    Initial Impressions
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#improving-the-model">
    Improving the Model
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#conclusions">
    Conclusions
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#naive-bayes-model">
    Naive Bayes Model
  </a>
<nav aria-label="Naive Bayes Model" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#issues-in-the-data">
    Issues in the Data
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#predictions">
    Predictions
  </a>
<nav aria-label="Predictions" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#initial-conclusion">
    Initial conclusion
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#the-confusion-matrix">
    The Confusion Matrix
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#accuracy">
    Accuracy
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sensitivity-specificity">
    Sensitivity &amp; Specificity
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#kappa">
    Kappa
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#roc-curves-and-auc">
    ROC Curves and AUC
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#matthews-correlation-coefficient-mcc">
    Matthew's Correlation Coefficient (MCC):
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#strengths-and-weaknesses">
    Strengths and Weaknesses
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#summary-of-metrics">
    Summary of Metrics
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#conclusion">
    Conclusion
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Regression/">
<span class="md-ellipsis">
    Regression
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../data%20exploration/">
<span class="md-ellipsis">
    Data exploration
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../ml%20overview/">
<span class="md-ellipsis">
    ML Work
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
<span class="md-ellipsis">
    Obsidian
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
            Obsidian
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../obsidian/copart%20internship/">
<span class="md-ellipsis">
    Copart internship
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../obsidian/portfolio%20cleanup/">
<span class="md-ellipsis">
    Portfolio cleanup
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#classification">
    Classification
  </a>
<nav aria-label="Classification" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#what-is-our-data">
    What is Our Data?
  </a>
<nav aria-label="What is Our Data?" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#reading-the-data">
    Reading the Data
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#training-data-exploration">
    Training Data Exploration
  </a>
<nav aria-label="Training Data Exploration" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#spliting-training-data">
    Spliting Training Data
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#textual-measurements">
    Textual Measurements
  </a>
<nav aria-label="Textual Measurements" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#text-analysis-conclusion">
    Text Analysis Conclusion
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#visual-analysis">
    Visual Analysis
  </a>
<nav aria-label="Visual Analysis" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#visual-analysis-conclusion">
    Visual Analysis Conclusion
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#classification-regression">
    Classification Regression
  </a>
<nav aria-label="Classification Regression" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#logistic-regression">
    Logistic Regression
  </a>
<nav aria-label="Logistic Regression" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#explanation">
    Explanation
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#looking-at-p-values">
    Looking at P-Values
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#probability-warning">
    Probability Warning
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#initial-impressions">
    Initial Impressions
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#improving-the-model">
    Improving the Model
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#conclusions">
    Conclusions
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#naive-bayes-model">
    Naive Bayes Model
  </a>
<nav aria-label="Naive Bayes Model" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#issues-in-the-data">
    Issues in the Data
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#predictions">
    Predictions
  </a>
<nav aria-label="Predictions" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#initial-conclusion">
    Initial conclusion
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#the-confusion-matrix">
    The Confusion Matrix
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#accuracy">
    Accuracy
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sensitivity-specificity">
    Sensitivity &amp; Specificity
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#kappa">
    Kappa
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#roc-curves-and-auc">
    ROC Curves and AUC
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#matthews-correlation-coefficient-mcc">
    Matthew's Correlation Coefficient (MCC):
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#strengths-and-weaknesses">
    Strengths and Weaknesses
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#summary-of-metrics">
    Summary of Metrics
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#conclusion">
    Conclusion
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<!--
  Copyright (c) 2016-2023 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->
<!-- Tags -->
<nav class="md-tags">
</nav>
<!-- Actions -->
<!--
  Hack: check whether the content contains a h1 headline. If it doesn't, the
  page title (or respectively site name) is used as the main headline.
-->
<h1>Classification</h1>
<!-- Page content -->
<h2 id="classification">Classification<a class="headerlink" href="#classification" title="Permanent link">¶</a></h2>
<p>This time we will be using linear models in order to classify observations. Linear models like logistic regression and Naive Bayes work by finding the probability of a target variable given a predictor variable. This means we are predicting a class as opposed to a continuous value like in linear regression. These models are great for data with outliers and are easy to implement and interpret. Linear regression isn’t very flexible however, and Naive Bayes makes a naive assumption that predictors are independent. </p>
<h3 id="what-is-our-data">What is Our Data?<a class="headerlink" href="#what-is-our-data" title="Permanent link">¶</a></h3>
<p>The weather data we used in our quantitative didn’t have a suitable categorical target field, so we are switching to <a href="https://www.kaggle.com/datasets/rdcmdev/adult-income-dataset">income census data</a>. The data has a great binary classification in the form of an IncomeClass attribute that only states whether a given person’s income is below or above 50k. We have plenty of categories for each person, and continuous measurements like age and work hours.</p>
<p>The census itself is from the year 1994, and spans various socieo-economic groups. We both trying to predict this income classification based on all of the data, as well as just get an understanding of some key predictors in the data.</p>
<p>With IncomeClass as our target, lets analyze the data!</p>
<h4 id="reading-the-data">Reading the Data<a class="headerlink" href="#reading-the-data" title="Permanent link">¶</a></h4>
<p>The data is stored as two files, with rows just delimited by commas, so we read them in to one whole data frame, and label the headers manual using our source as a reference. It’s worth noting that this data was extracted with the intention of creating a classification model, so the two files are meant to be training and test data, but we are going to re-distribute the data later.<br/>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="n">income_train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.table</span><span class="p">(</span><span class="s">"adult.data"</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s">","</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="n">income_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.table</span><span class="p">(</span><span class="s">"adult.test"</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s">","</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="n">income</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rbind</span><span class="p">(</span><span class="n">income_test</span><span class="p">,</span><span class="w"> </span><span class="n">income_train</span><span class="p">)</span>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="nf">colnames</span><span class="p">(</span><span class="n">income</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">"Age"</span><span class="p">,</span><span class="w"> </span><span class="s">"WorkClass"</span><span class="p">,</span><span class="w"> </span><span class="s">"Weight"</span><span class="p">,</span><span class="w"> </span><span class="s">"Education"</span><span class="p">,</span><span class="w"> </span><span class="s">"YearsEdu"</span><span class="p">,</span><span class="w"> </span><span class="s">"Marital-Status"</span><span class="p">,</span><span class="w"> </span><span class="s">"Job"</span><span class="p">,</span><span class="w"> </span><span class="s">"Relationship"</span><span class="p">,</span><span class="w"> </span><span class="s">"Race"</span><span class="p">,</span><span class="w"> </span><span class="s">"Sex"</span><span class="p">,</span><span class="w"> </span><span class="s">"CapitalGain"</span><span class="p">,</span><span class="w"> </span><span class="s">"CapitalLoss"</span><span class="p">,</span><span class="w"> </span><span class="s">"HoursWorked"</span><span class="p">,</span><span class="w"> </span><span class="s">"NativeCountry"</span><span class="p">,</span><span class="w"> </span><span class="s">"IncomeClass"</span><span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="c1">#Just to check to make sure it read properly</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="nf">str</span><span class="p">(</span><span class="n">income</span><span class="p">)</span>
</code></pre></div><br/>
Now we want to turn the qualitative data into factors.</p>
<p>Find all attributes of income that are non-numeric</p>
<ul>
<li>sapply() returns a logical object of every attribute run through the given function</li>
<li>which() returns all of the true indices of a logical object</li>
<li>income[,<object>] extracts the attributes (See help(Extract))</object></li>
<li>We then lapply, with as.factor forcing them to be factors in a list</li>
</ul>
<p>Then just factor them.<br/>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="c1"># Note here that while sapply returns a vector, lapply returns a list</span>
<a href="#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a><span class="n">income</span><span class="p">[,</span><span class="w"> </span><span class="nf">sapply</span><span class="p">(</span><span class="n">income</span><span class="p">,</span><span class="w"> </span><span class="n">is.character</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lapply</span><span class="p">(</span><span class="n">income</span><span class="p">[,</span><span class="w"> </span><span class="nf">sapply</span><span class="p">(</span><span class="n">income</span><span class="p">,</span><span class="w"> </span><span class="n">is.character</span><span class="p">)],</span><span class="w"> </span><span class="n">as.factor</span><span class="p">)</span>
<a href="#__codelineno-1-3" id="__codelineno-1-3" name="__codelineno-1-3"></a><span class="c1"># Checking our work</span>
<a href="#__codelineno-1-4" id="__codelineno-1-4" name="__codelineno-1-4"></a><span class="nf">str</span><span class="p">(</span><span class="n">income</span><span class="p">)</span>
</code></pre></div></p>
<p>Now the data is a bit cleaner we can start to look at it!<br/>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-2-1" id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="nf">summary</span><span class="p">(</span><span class="n">income</span><span class="p">)</span>
</code></pre></div><br/>
Now that we can really see our factor’s options, I see a couple skewed data points:</p>
<ul>
<li>Twice as many men as women! Hope those numbers are better in 2022!</li>
<li>A large percent of the data is for natives to the US, which is kind of expected</li>
<li>Weight: Now, this represent what census takers thought a particular row represented the whole of the dataset. I must admit at the time I don’t know how to account for statistical weight, but considering our model only needs to match training data, not other data from 1994, we are safe to ignore it.</li>
</ul>
<p>The data looks very clean! Except for a bit of an anomaly with how the Target column, IncomeClass is stored. Some levels have a “.” at the end, which we would like to remove. So lets go ahead and condense that, remove the Weight attribute, and create our training and test data.</p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-3-1" id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="c1"># Simply just reassign the levels</span>
<a href="#__codelineno-3-2" id="__codelineno-3-2" name="__codelineno-3-2"></a><span class="nf">levels</span><span class="p">(</span><span class="n">income</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">"&lt;=50k"</span><span class="p">,</span><span class="w"> </span><span class="s">"&lt;=50k"</span><span class="p">,</span><span class="w"> </span><span class="s">"&gt;50k"</span><span class="p">,</span><span class="w"> </span><span class="s">"&gt;50k"</span><span class="p">)</span>
<a href="#__codelineno-3-3" id="__codelineno-3-3" name="__codelineno-3-3"></a><span class="nf">levels</span><span class="p">(</span><span class="n">income</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
<a href="#__codelineno-3-4" id="__codelineno-3-4" name="__codelineno-3-4"></a><span class="c1"># Then remove the attribute weight using it's index</span>
<a href="#__codelineno-3-5" id="__codelineno-3-5" name="__codelineno-3-5"></a><span class="n">income</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">income</span><span class="p">[,</span><span class="w"> </span><span class="m">-3</span><span class="p">]</span>
<a href="#__codelineno-3-6" id="__codelineno-3-6" name="__codelineno-3-6"></a><span class="n">income</span>
</code></pre></div>
<p>Then we are good to start exploring!</p>
<h2 id="training-data-exploration">Training Data Exploration<a class="headerlink" href="#training-data-exploration" title="Permanent link">¶</a></h2>
<h3 id="spliting-training-data">Spliting Training Data<a class="headerlink" href="#spliting-training-data" title="Permanent link">¶</a></h3>
<p>We are splitting training data on a 80/20 split<br/>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-4-1" id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="nf">set.seed</span><span class="p">(</span><span class="m">42069</span><span class="p">)</span>
<a href="#__codelineno-4-2" id="__codelineno-4-2" name="__codelineno-4-2"></a><span class="n">trainindex</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="nf">nrow</span><span class="p">(</span><span class="n">income</span><span class="p">),</span><span class="nf">nrow</span><span class="p">(</span><span class="n">income</span><span class="p">)</span><span class="o">*</span><span class="n">.</span><span class="m">8</span><span class="p">,</span><span class="n">replace</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>
<a href="#__codelineno-4-3" id="__codelineno-4-3" name="__codelineno-4-3"></a><span class="n">train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">income</span><span class="p">[</span><span class="n">trainindex</span><span class="p">,]</span>
<a href="#__codelineno-4-4" id="__codelineno-4-4" name="__codelineno-4-4"></a><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">income</span><span class="p">[</span><span class="o">-</span><span class="n">trainindex</span><span class="p">,]</span>
<a href="#__codelineno-4-5" id="__codelineno-4-5" name="__codelineno-4-5"></a><span class="c1"># Cleaning up earlier data</span>
<a href="#__codelineno-4-6" id="__codelineno-4-6" name="__codelineno-4-6"></a><span class="nf">rm</span><span class="p">(</span><span class="s">"income"</span><span class="p">,</span><span class="w"> </span><span class="s">"income_test"</span><span class="p">,</span><span class="w"> </span><span class="s">"income_train"</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="textual-measurements">Textual Measurements<a class="headerlink" href="#textual-measurements" title="Permanent link">¶</a></h3>
<p>And what does that training data look like!</p>
<p>We would want to use different metrics, like mean, or count our factors:<br/>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-5-1" id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="nf">mean</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">Age</span><span class="p">)</span>
<a href="#__codelineno-5-2" id="__codelineno-5-2" name="__codelineno-5-2"></a><span class="nf">nlevels</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">WorkClass</span><span class="p">)</span>
</code></pre></div></p>
<p>But we can just do that in <code>summary()</code>.</p>
<p><div class="highlight"><pre><span></span><code><a href="#__codelineno-6-1" id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="nf">summary</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
</code></pre></div><br/>
The summary above is good for making sure there is no errors in the data, and of course skews we can deal with. For this data, there sure are a lot of men native to America, but that as said earlier is expected. Looking a bit more:</p>
<p><div class="highlight"><pre><span></span><code><a href="#__codelineno-7-1" id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="nf">sum</span><span class="p">(</span><span class="nf">is.na</span><span class="p">(</span><span class="n">train</span><span class="p">))</span>
<a href="#__codelineno-7-2" id="__codelineno-7-2" name="__codelineno-7-2"></a><span class="nf">head</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<a href="#__codelineno-7-3" id="__codelineno-7-3" name="__codelineno-7-3"></a><span class="nf">tail</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
</code></pre></div><br/>
We get an example of whats at the end and start of the data set, and make sure there are no NA’s. The census people really keep their data clean.</p>
<p>For one more look lets see some correlation data. Curious how much capital loss went up with age? We can see below… well not much honestly.<br/>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-8-1" id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="nf">cor</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">Age</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">CapitalLoss</span><span class="p">)</span>
</code></pre></div></p>
<h4 id="text-analysis-conclusion">Text Analysis Conclusion<a class="headerlink" href="#text-analysis-conclusion" title="Permanent link">¶</a></h4>
<p>We fear the skew of my data towards 1 type of person (Married Men about to hit their 40’s) will make the model’s we produce perform well for our dataset, but fail to get any real world accuracy. Obviously if this model was actually destined to predict in the real world if people’s income was above or below a certain level (in the 1990’s), well if we had all this data we would probably already know their income. So the model is a pointless but fun experiment…</p>
<p>Regardless it is worth noting that a transformation of the data before running logistic regression or naive bayes could produce better results, but it is beyond the scope of this experiment.</p>
<p>While it is probably a realistic distribution of income class (3 people with less than 50k for every person over 50k), the data may just guess that everyone doesn’t make that much money due to the skew. This actually is a lot more important then skewed predictors, as our eventual precision/recall could be quite bad. For now, simply observing this is good enough, but this should be onsidered for the final analysis. (And perhaps in our comparision between Bayes and logistic regression).</p>
<h3 id="visual-analysis">Visual Analysis<a class="headerlink" href="#visual-analysis" title="Permanent link">¶</a></h3>
<p>We want to see how our target, IncomeClass relates to our numerical data:<br/>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-9-1" id="__codelineno-9-1" name="__codelineno-9-1"></a><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">train</span><span class="o">$</span><span class="n">Age</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">""</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">"Income"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">"Age"</span><span class="p">)</span>
<a href="#__codelineno-9-2" id="__codelineno-9-2" name="__codelineno-9-2"></a><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">train</span><span class="o">$</span><span class="n">CapitalLoss</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">""</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">"Income"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">"Capital Loss"</span><span class="p">)</span>
<a href="#__codelineno-9-3" id="__codelineno-9-3" name="__codelineno-9-3"></a><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">train</span><span class="o">$</span><span class="n">CapitalGain</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">""</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">"Income"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">"Capital Gain"</span><span class="p">)</span>
<a href="#__codelineno-9-4" id="__codelineno-9-4" name="__codelineno-9-4"></a><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">train</span><span class="o">$</span><span class="n">HoursWorked</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">""</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">"Income"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">"Hours Worked"</span><span class="p">)</span>
</code></pre></div></p>
<p>Numerical trends are just easier to spot, especially the effect of age on IncomeClass. You can definitely see in the ease graphs, particular age and hours worked, that there are <em>some</em> grounds to predict this income classification based on the predictor data.</p>
<p>For another view:<br/>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-10-1" id="__codelineno-10-1" name="__codelineno-10-1"></a><span class="nf">cdplot</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">Age</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
<a href="#__codelineno-10-2" id="__codelineno-10-2" name="__codelineno-10-2"></a><span class="n">breaks</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="m">0</span><span class="o">:</span><span class="m">10</span><span class="p">)</span><span class="o">*</span><span class="m">10</span>
<a href="#__codelineno-10-3" id="__codelineno-10-3" name="__codelineno-10-3"></a><span class="nf">plot</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">IncomeClass</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="nf">findInterval</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">HoursWorked</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="p">))</span>
<a href="#__codelineno-10-4" id="__codelineno-10-4" name="__codelineno-10-4"></a><span class="nf">plot</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">Sex</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
</code></pre></div></p>
<p>Above we can see a couple trends relating to Income Class:</p>
<ul>
<li>Women don’t make as much as men</li>
<li>It seems the more hours worked, the higher your chances of making it over 50k</li>
<li>Right around 50 years old is when people were the most likely to make &gt;50k</li>
</ul>
<h4 id="visual-analysis-conclusion">Visual Analysis Conclusion<a class="headerlink" href="#visual-analysis-conclusion" title="Permanent link">¶</a></h4>
<p>There are so many different factors in this data, that we think assuming the factors are independent could harm the <br/>
eventual accuracy of our linear models. While we can graph individual factors relation to the target, there are complicated relationships between the predictor data. We may be able to guess that more education would lead to a higher income, but an in-depth analysis of how gender or native country may hamper access to education isnt represented by just the relationship from gender to income. To the final product, it just <em>looks</em> like you can bet women make less money, even if that may be due to a compaction of other factors.</p>
<p>Just a couple trends are seen above, and they still tell us that there is some merit to this data being alble to predict relations between our predictors and our target. Now it is time to see if all of those predictors together have a good chance of classifying them into the &gt;50k or &lt;=50k levels.</p>
<h2 id="classification-regression">Classification Regression<a class="headerlink" href="#classification-regression" title="Permanent link">¶</a></h2>
<h3 id="logistic-regression">Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permanent link">¶</a></h3>
<p><div class="highlight"><pre><span></span><code><a href="#__codelineno-11-1" id="__codelineno-11-1" name="__codelineno-11-1"></a><span class="n">glm1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">glm</span><span class="p">(</span><span class="n">IncomeClass</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="o">=</span><span class="n">binomial</span><span class="p">)</span>
<a href="#__codelineno-11-2" id="__codelineno-11-2" name="__codelineno-11-2"></a><span class="nf">summary</span><span class="p">(</span><span class="n">glm1</span><span class="p">)</span>
</code></pre></div><br/>
Ah! Well we sure do get to get to view the impact of every level (dummy variable) on the output model. Before analyzing the coefficients predicted by the model, I want to examine which attributes were better for the model as compared to others.</p>
<h4 id="explanation">Explanation<a class="headerlink" href="#explanation" title="Permanent link">¶</a></h4>
<p>The data produced by the model is the coefficients of each predictor. The coefficient represents the effect the value of the predictor has on our target. If we have a positive coefficient like age, as age goes up we can expect the probability of our target (IncomeClass) to go up. The final model then considers each of these coefficients in it’s prediction. Different parts of the data are:</p>
<ul>
<li>Deviance Residuals:</li>
<li>The Null Deviance:</li>
<li>Residual Deviance:</li>
<li>Degrees of Freedom:</li>
<li>AIC:</li>
<li>Fisher Scoring Iterations:</li>
<li>Standard Error:</li>
<li>Z Value:</li>
<li>P Value:</li>
</ul>
<h4 id="looking-at-p-values">Looking at P-Values<a class="headerlink" href="#looking-at-p-values" title="Permanent link">¶</a></h4>
<p>A coefficient estimate’s p-values can tell us which features are valuable predictors. However, because the data is mostly qualitative, each level of each factor has a different impact on the data. </p>
<p>WorkClass seems like it is a good predictor <em>overall</em>, but if a given person’s WorkClass is Never-worked, well the p-value is huge! Now, obviously if you have never worked your income isn’t going to be very high, and the model estimates a high negative correlation. Yet the P-Value is super high!</p>
<p>This could be due to a number of factors:</p>
<ul>
<li>The sample size of people who have never worked in this data is much smaller than the total population.</li>
<li>Our target factor is skewed, so this predictor can’t differ too much from the null hypothesis </li>
<li>People who have never worked have varying life experiences, so the final accuracy of their coefficients isn’t going to be able to fit the data</li>
</ul>
<p>As humans we can see the this coefficient should be significant, so perhaps this isn’t the best dataset for logistic regression. The summary of the model basically is this: </p>
<blockquote>
<p>While factors that you would expect to negatively impact income class do have large negative coefficents their p-values are very large because the overall target is very skewed (probably) towards what they are predicting (low income).</p>
</blockquote>
<h4 id="probability-warning">Probability Warning<a class="headerlink" href="#probability-warning" title="Permanent link">¶</a></h4>
<p>Another issue with the data is the warning:</p>
<blockquote>
<p><code>Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></p>
</blockquote>
<p>This error occurs when our model fits the data so well it is most likely too perfect. This means there is <em>somewhat likely</em> an error in our data. We can check it by looking at a couple predictions:</p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-12-1" id="__codelineno-12-1" name="__codelineno-12-1"></a><span class="nf">head</span><span class="p">(</span><span class="nf">predict</span><span class="p">(</span><span class="n">glm1</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s">"response"</span><span class="p">),</span><span class="w"> </span><span class="m">30</span><span class="p">)</span><span class="w"> </span><span class="c1"># Looking at some probabilities</span>
</code></pre></div>
<p>Looking at just 30 fitted probabilities we see that not every single probability is 1 or 0, but another warning:</p>
<blockquote>
<p>Warning: prediction from a rank-deficent fit may be misleading</p>
</blockquote>
<p>This means our number of linearly independent columns does not equal the number of parameters. Funny enough, the actual model throws out what it believes are perfectly colinear variables, causing this warning. The solution would then be to remove the colinear attributes, which will be done in just a moment.</p>
<h4 id="initial-impressions">Initial Impressions<a class="headerlink" href="#initial-impressions" title="Permanent link">¶</a></h4>
<p>Dismissing those issues, good predictors are:</p>
<ul>
<li>Age</li>
<li>Work Class</li>
<li>Education (Specifically higher education)</li>
<li>Job</li>
<li>Marriage Status</li>
<li>Sex</li>
<li>Hours Worked</li>
</ul>
<p>This model makes me wonder what would happen if we selected a sample from this dataset that is less skewed, but I’m unsure what this would do to the accuracy of this model in the real world.</p>
<h4 id="improving-the-model">Improving the Model<a class="headerlink" href="#improving-the-model" title="Permanent link">¶</a></h4>
<p>We wanted to see if removing predictors would help the overall accuracy, especially given that our predictors are somewhat dependent on each other. A brief search revealed that the anova function can show how adding each predictor effects the model.</p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-13-1" id="__codelineno-13-1" name="__codelineno-13-1"></a><span class="nf">anova</span><span class="p">(</span><span class="n">glm1</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">=</span><span class="s">"Chisq"</span><span class="p">)</span>
</code></pre></div>
<p>Looking below, we can tell that each addition to the model is statistically relevant</p>
<h4 id="conclusions">Conclusions<a class="headerlink" href="#conclusions" title="Permanent link">¶</a></h4>
<p>There are issues with the data, mostly a high bias and a skewed target variable, but our current model still could give good predictions given a similar data set. If you took another sample of census data just after this one it could probably predict income class a bit</p>
<h3 id="naive-bayes-model">Naive Bayes Model<a class="headerlink" href="#naive-bayes-model" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-14-1" id="__codelineno-14-1" name="__codelineno-14-1"></a><span class="nf">library</span><span class="p">(</span><span class="n">e1071</span><span class="p">)</span>
<a href="#__codelineno-14-2" id="__codelineno-14-2" name="__codelineno-14-2"></a><span class="n">nb1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">naiveBayes</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">IncomeClass</span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
<a href="#__codelineno-14-3" id="__codelineno-14-3" name="__codelineno-14-3"></a><span class="n">nb1</span>
</code></pre></div>
<p>Naive Bayes produces a model that first finds the prior probability (A-priori, or the probability of having &lt;=50k or &gt;50k with no considerations of other data) and then finds the probability of the income given each condition independently. For example the table for Sex states that the probability that someone is female given that you make less than 50k is ~40%, while if a person makes more than 50k the chance they are a woman is ~15%.</p>
<p>We also see the results for quantified predictors. For a continuous predictor like age, the mean age for people &lt;=50k is 36.85352 while people &gt;50k are older at a mean of 44.32006 years old.</p>
<p>The model may just be finding the independent probabilities of the target event given each predictor but using all of the probabilities at once can provide a pretty good guess. Good enough to predict our training data!</p>
<h4 id="issues-in-the-data">Issues in the Data<a class="headerlink" href="#issues-in-the-data" title="Permanent link">¶</a></h4>
<p>It’s worth noting once again that our predictors may not be completely independent but our model here assumes they are. That is why we call it naive! With such a large amount of data, probability can overcome the shortcomings of this assumption and we could get reasonably accurate predictions</p>
<h3 id="predictions">Predictions<a class="headerlink" href="#predictions" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-15-1" id="__codelineno-15-1" name="__codelineno-15-1"></a><span class="n">p1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">glm1</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="o">=</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s">"response"</span><span class="p">)</span>
<a href="#__codelineno-15-2" id="__codelineno-15-2" name="__codelineno-15-2"></a><span class="n">pred1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">ifelse</span><span class="p">(</span><span class="n">p1</span><span class="o">&gt;</span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="s">"&gt;50k"</span><span class="p">,</span><span class="w"> </span><span class="s">"&lt;=50k"</span><span class="p">)</span>
<a href="#__codelineno-15-3" id="__codelineno-15-3" name="__codelineno-15-3"></a><span class="nf">head</span><span class="p">(</span><span class="n">pred1</span><span class="p">)</span>
<a href="#__codelineno-15-4" id="__codelineno-15-4" name="__codelineno-15-4"></a><span class="nf">head</span><span class="p">(</span><span class="n">test</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
<a href="#__codelineno-15-5" id="__codelineno-15-5" name="__codelineno-15-5"></a><span class="n">cm1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">caret</span><span class="o">::</span><span class="nf">confusionMatrix</span><span class="p">(</span><span class="nf">as.factor</span><span class="p">(</span><span class="n">pred1</span><span class="p">),</span><span class="w"> </span><span class="n">reference</span><span class="o">=</span><span class="n">test</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
<a href="#__codelineno-15-6" id="__codelineno-15-6" name="__codelineno-15-6"></a><span class="n">cm1</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-16-1" id="__codelineno-16-1" name="__codelineno-16-1"></a><span class="n">p2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">nb1</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="o">=</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s">"class"</span><span class="p">)</span>
<a href="#__codelineno-16-2" id="__codelineno-16-2" name="__codelineno-16-2"></a><span class="nf">head</span><span class="p">(</span><span class="n">p2</span><span class="p">)</span>
<a href="#__codelineno-16-3" id="__codelineno-16-3" name="__codelineno-16-3"></a><span class="nf">head</span><span class="p">(</span><span class="n">test</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
<a href="#__codelineno-16-4" id="__codelineno-16-4" name="__codelineno-16-4"></a><span class="n">cm2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">caret</span><span class="o">::</span><span class="nf">confusionMatrix</span><span class="p">(</span><span class="nf">as.factor</span><span class="p">(</span><span class="n">p2</span><span class="p">),</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
<a href="#__codelineno-16-5" id="__codelineno-16-5" name="__codelineno-16-5"></a><span class="n">cm2</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-17-1" id="__codelineno-17-1" name="__codelineno-17-1"></a><span class="n">cm1</span><span class="o">$</span><span class="n">byClass</span>
</code></pre></div>
<h4 id="initial-conclusion">Initial conclusion<a class="headerlink" href="#initial-conclusion" title="Permanent link">¶</a></h4>
<p>The initial conclusion to be drawn from our predictions is that our accuracy for both our models is okay, and our logistic regression model did better than our Naive Bayes. This could probably be due to Naive Bayes often doing better with small data sets while logistic regression works better with large datasets. On the other hand the logistic regression model might have still been overwhelmed by the amount of factors, and the accuracy was only ~84%.</p>
<p>The confusion matrix tells us True Positive, False Positive, True Negative, and False Negative results from applying the model to the test data. We can use the ratios between these numbers to evaluate useful metrics like accuracy or sensitivity.</p>
<h4 id="the-confusion-matrix">The Confusion Matrix<a class="headerlink" href="#the-confusion-matrix" title="Permanent link">¶</a></h4>
<p><div class="highlight"><pre><span></span><code><a href="#__codelineno-18-1" id="__codelineno-18-1" name="__codelineno-18-1"></a>          Reference
<a href="#__codelineno-18-2" id="__codelineno-18-2" name="__codelineno-18-2"></a>Prediction &lt;=50k &gt;50k
<a href="#__codelineno-18-3" id="__codelineno-18-3" name="__codelineno-18-3"></a>     &lt;=50k  6898 1225
<a href="#__codelineno-18-4" id="__codelineno-18-4" name="__codelineno-18-4"></a>     &gt;50k    498 1148
</code></pre></div><br/>
Just for an example we are looking at the naive bayes confusion matrix.</p>
<ul>
<li>6898: The number of True Positives</li>
<li>1148: The number of True Negatives</li>
<li>498:  The number of False Negatives</li>
<li>1225: The number of False Positives</li>
</ul>
<p>We can use these to calculate other metrics</p>
<h4 id="accuracy">Accuracy<a class="headerlink" href="#accuracy" title="Permanent link">¶</a></h4>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-19-1" id="__codelineno-19-1" name="__codelineno-19-1"></a>Logistic R.: ~85%
<a href="#__codelineno-19-2" id="__codelineno-19-2" name="__codelineno-19-2"></a>Naive Bayes: ~82%
</code></pre></div>
<p>The diagonals, or our true results, divided by all of our predictions is our accuracy, or the percentage we were correct. As you can see, our logistic regression model was accurate more of the time. Most likely because it thrived more with the large amount of data.</p>
<h4 id="sensitivity-specificity">Sensitivity &amp; Specificity<a class="headerlink" href="#sensitivity-specificity" title="Permanent link">¶</a></h4>
<p><div class="highlight"><pre><span></span><code><a href="#__codelineno-20-1" id="__codelineno-20-1" name="__codelineno-20-1"></a>Logistic R.: 0.9287 and 0.5874
<a href="#__codelineno-20-2" id="__codelineno-20-2" name="__codelineno-20-2"></a>Naive Bayes: 0.9327 and 0.4838
</code></pre></div><br/>
Naive Bayes had a higher sensitivity, which is the number of true positives out of true positives + false negatives (the number of positives in the data). If we were trying to perhaps locate all people with “low” income but didn’t care about our accuracy with people above 50k, the stat shows naive bayes could be useful.</p>
<p>Specificity is the measure of true negatives in the negative class. We can tell then that we were much better at identifying our people with &lt;=50k income than people with &gt;50k income. However, logistic regression was still better than Naive Bayes in this stat.</p>
<p>Well you ignore part of the data and perhaps get to ignore issues ini your model (like ignoring a bunch of false negatives), these are great for getting what matters out of data.</p>
<h4 id="kappa">Kappa<a class="headerlink" href="#kappa" title="Permanent link">¶</a></h4>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-21-1" id="__codelineno-21-1" name="__codelineno-21-1"></a>Logistic R.: 0.5519 
<a href="#__codelineno-21-2" id="__codelineno-21-2" name="__codelineno-21-2"></a>Naive Bayes: 0.4648 
</code></pre></div>
<p>Woah! These aren’t the best numbers, but considering this is a measure of accuracy that corrects for prediction by chance, I’m surprised the number is so high. The data set was skewed, it seemed a large margin of the success of our models was due to random chance. According to a reference on kappa scores though, these numbers are in “moderate agreement” with what is expected.</p>
<p>Kappa is great for regarding datasets where the random chance of getting a prediction high is right. Of course, there isn’t a consensus on what the number means on a scale, but its still generally useful.</p>
<h4 id="roc-curves-and-auc">ROC Curves and AUC<a class="headerlink" href="#roc-curves-and-auc" title="Permanent link">¶</a></h4>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-22-1" id="__codelineno-22-1" name="__codelineno-22-1"></a><span class="nf">library</span><span class="p">(</span><span class="n">ROCR</span><span class="p">)</span>
<a href="#__codelineno-22-2" id="__codelineno-22-2" name="__codelineno-22-2"></a><span class="nf">head</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span>
<a href="#__codelineno-22-3" id="__codelineno-22-3" name="__codelineno-22-3"></a><span class="nf">head</span><span class="p">(</span><span class="n">test</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
<a href="#__codelineno-22-4" id="__codelineno-22-4" name="__codelineno-22-4"></a><span class="n">pr</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">prediction</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
<a href="#__codelineno-22-5" id="__codelineno-22-5" name="__codelineno-22-5"></a><span class="n">prf</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">performance</span><span class="p">(</span><span class="n">pr</span><span class="p">,</span><span class="w"> </span><span class="n">measure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">"tpr"</span><span class="p">,</span><span class="w"> </span><span class="n">x.measure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">"fpr"</span><span class="p">)</span>
<a href="#__codelineno-22-6" id="__codelineno-22-6" name="__codelineno-22-6"></a><span class="nf">plot</span><span class="p">(</span><span class="n">prf</span><span class="p">)</span>
<a href="#__codelineno-22-7" id="__codelineno-22-7" name="__codelineno-22-7"></a><span class="c1"># Compute AUC</span>
<a href="#__codelineno-22-8" id="__codelineno-22-8" name="__codelineno-22-8"></a><span class="n">auc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">performance</span><span class="p">(</span><span class="n">pr</span><span class="p">,</span><span class="w"> </span><span class="n">measure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">"auc"</span><span class="p">)</span>
<a href="#__codelineno-22-9" id="__codelineno-22-9" name="__codelineno-22-9"></a><span class="n">auc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">auc</span><span class="o">@</span><span class="n">y.values</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span>
<a href="#__codelineno-22-10" id="__codelineno-22-10" name="__codelineno-22-10"></a><span class="n">auc</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-23-1" id="__codelineno-23-1" name="__codelineno-23-1"></a><span class="nf">library</span><span class="p">(</span><span class="n">ROCR</span><span class="p">)</span>
<a href="#__codelineno-23-2" id="__codelineno-23-2" name="__codelineno-23-2"></a><span class="n">p2raw</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">nb1</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="o">=</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s">"raw"</span><span class="p">)[,</span><span class="m">2</span><span class="p">]</span>
<a href="#__codelineno-23-3" id="__codelineno-23-3" name="__codelineno-23-3"></a><span class="n">pr2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">prediction</span><span class="p">(</span><span class="n">p2raw</span><span class="p">,</span><span class="nf">as.numeric</span><span class="p">(</span><span class="n">test</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">))</span>
<a href="#__codelineno-23-4" id="__codelineno-23-4" name="__codelineno-23-4"></a><span class="n">prf2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">performance</span><span class="p">(</span><span class="n">pr2</span><span class="p">,</span><span class="w"> </span><span class="n">measure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">"tpr"</span><span class="p">,</span><span class="w"> </span><span class="n">x.measure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">"fpr"</span><span class="p">)</span>
<a href="#__codelineno-23-5" id="__codelineno-23-5" name="__codelineno-23-5"></a><span class="nf">plot</span><span class="p">(</span><span class="n">prf2</span><span class="p">)</span>
<a href="#__codelineno-23-6" id="__codelineno-23-6" name="__codelineno-23-6"></a>
<a href="#__codelineno-23-7" id="__codelineno-23-7" name="__codelineno-23-7"></a><span class="c1"># Compute AUC</span>
<a href="#__codelineno-23-8" id="__codelineno-23-8" name="__codelineno-23-8"></a><span class="n">auc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">performance</span><span class="p">(</span><span class="n">pr2</span><span class="p">,</span><span class="w"> </span><span class="n">measure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">"auc"</span><span class="p">)</span>
<a href="#__codelineno-23-9" id="__codelineno-23-9" name="__codelineno-23-9"></a><span class="n">auc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">auc</span><span class="o">@</span><span class="n">y.values</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span>
<a href="#__codelineno-23-10" id="__codelineno-23-10" name="__codelineno-23-10"></a><span class="n">auc</span>
</code></pre></div>
<h4 id="matthews-correlation-coefficient-mcc">Matthew’s Correlation Coefficient (MCC):<a class="headerlink" href="#matthews-correlation-coefficient-mcc" title="Permanent link">¶</a></h4>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-24-1" id="__codelineno-24-1" name="__codelineno-24-1"></a><span class="c1"># Logistic Regression</span>
<a href="#__codelineno-24-2" id="__codelineno-24-2" name="__codelineno-24-2"></a><span class="n">mltools</span><span class="o">::</span><span class="nf">mcc</span><span class="p">(</span><span class="nf">as.factor</span><span class="p">(</span><span class="n">pred1</span><span class="p">),</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-25-1" id="__codelineno-25-1" name="__codelineno-25-1"></a><span class="c1"># Naive Bayes</span>
<a href="#__codelineno-25-2" id="__codelineno-25-2" name="__codelineno-25-2"></a><span class="n">mltools</span><span class="o">::</span><span class="nf">mcc</span><span class="p">(</span><span class="n">p2</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">IncomeClass</span><span class="p">)</span>
</code></pre></div>
<p>.4771213 is smack dab in between a perfect model (1) and a model that is perfectly average (0). Pretty good!</p>
<h3 id="strengths-and-weaknesses">Strengths and Weaknesses<a class="headerlink" href="#strengths-and-weaknesses" title="Permanent link">¶</a></h3>
<p>Logistic Regression basically is attempting to draw a line between classes. It ends up being quite computationally inexpensive, easy to understand, and does its job well if classes are easy to separate. But because of it’s simplicity as a line, it just isn’t complex enough to capture complex non-linear decision boundaries. Naive Bayes is also simple, but with the added bonus that it works well with high dimensions (complex data sets) <em>if</em> they aren’t too big. It’s simple however because it assumes variables are independent, and ends up lacking with larger data sets.</p>
<h3 id="summary-of-metrics">Summary of Metrics<a class="headerlink" href="#summary-of-metrics" title="Permanent link">¶</a></h3>
<p>Accuracy being the ratio of correct predictions to incorrect predictions, it is broadly useful. But often we are searching for subsections of accuracy. Sensitivity is good for detecting the amount we get one (the positive) class and ignores the other. Specificity on the other hand is the ratio of correct negative classes. This means we can use these metrics to see how ell our data is at guessing what matters in the at. If we want to see general accuracy, but account for the chance of getting the prediction randomly correct, Kappa is great for checking that.</p>
<p>Now ROC… well it graphs the true positive rate and the false positive rate (sensitivity and specificity). Unfortunately we tried til the deadline to get this to work for Naive Bayes but we swear we understand what it means! The name, Receiver Operator Characteristic curve comes from signal detection theory so it doesn’t help much to remind what it means. However, basically it graphs the trade off of a model between sensitivity and specificity. The Area under the curve then represents how much the model is capable of distinguishing between classes.</p>
<p>The MCC is a metric that basically gives a good value if you get a good reliable rate in all 4 values of the confusion matrix. The values are considered in proportional the size of the positive and negative values. Rather then combining the sensitivity and specificity of a metric into a single metric (like with an F1-Score), MCC considers the size of of negative samples. MCC’s account for class distribution makes it great at providing an accuracy rating for the whole model rated from -1 to 1.</p>
<h2 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link">¶</a></h2>
<p>We have 1 large takeaway from this data, linear data has limitations, and none of that is helped by having a skewed data set. In the future we would like to select a data set that has less of skewed target, or at least try to sample this data at a better ratio again. It was fun to look at though!</p>
<!-- Source file information -->
<!-- taken from 
https://github.com/squidfunk/mkdocs-material/blob/master/src/partials/source-file.html -->
<hr/>
<div class="md-source-file">
<small>
<!-- mkdocs-git-revision-date-localized-plugin -->
<u>Last update</u> :
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">25 octobre 2023</span>
<!-- mkdocs-git-revision-date-plugin -->
<br/>
<u>Created</u> :
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">25 octobre 2023</span>
<br/>
<u>Auteur</u> : Zachary Canoot &amp; Gray Simpson
        
        
    </small>
</div>
<!-- Was this page helpful? -->
<!-- Comment system -->
<!-- Giscus -->
<!-- Giscus -->
<script> 
    try {
      const index = document.querySelector('h1').innerHTML;
      if (index === "Index") {
        document.querySelector('h1').innerHTML = "Classification";
      }
    } catch (error) {
      // console.log(error);
    }
  </script>
</article>
</div>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["navigation.indexes", "navigation.top", "navigation.tabs", "navigation.tabs.sticky", "navigation.expand", "search.suggest", "search.highlight"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
<script src="../../assets/javascripts/bundle.aecac24b.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/ObsidianPublisher/assets@main/dist/javascript.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});})</script></body>
</html>